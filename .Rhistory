length(dt)
dt[1]
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
print(i)
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
dim(DT)
head(DT)
gas_data = lapply(87:172, function(i) get_Comtrade(r = country_id[i], cc = "271111%2C271121"))
chunk1 = DT
gas_data = lapply(87:172, function(i) get_Comtrade(r = country_id[i], cc = "271111%2C271121"))
length(gas_data)
dt = gas_data[!is.na(gas_data)]
length(dt)
head(DT)
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
head(DT)
chunk2 = DT
chunk12 = rbind(chunk1,chunk2)
length(all_countries)
all_countries
length(country_id)
length(country_id)-172
gas_data = lapply(173:254, function(i) get_Comtrade(r = country_id[i], cc = "271111%2C271121"))
length(gas_data)
dt = gas_data[!is.na(gas_data)]
length(dt)
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
tail(chunk12)
chunk3 = DT
chunk123 = rbind(chunk12,chunk3)
DT = chunk123
write.csv(DT, file = "/Users/bendenisshaffer/Box Sync/UM Fall 2017/SI 608/Project/Data/gas_trade.csv")
DTT = DT %>% select(Reporter,Partner,Trade_Value__US__,Netweight__kg_,
Reporter_ISO, Partner_ISO, Commodity, Year) %>% filter(Partner != "World", Reporter != "World")
write.csv(DTT, file = "/Users/bendenisshaffer/Box Sync/UM Fall 2017/SI 608/Project/Data/clean_gas_trade.csv")
sugar_data = lapply(1:85, function(i) get_Comtrade(r = country_id[i], cc = "170111"))
dt = sugar_data[!is.na(sugar_data)]
length(dt)
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
chunk1 = DT
sugar_data = lapply(86:170, function(i) get_Comtrade(r = country_id[i], cc = "170111"))
chunk2 = DT
dt = sugar_data[!is.na(sugar_data)]
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
chunk2 = DT
chunk12 = rbind(chunk1,chunk2)
length(country_id)
sugar_data = lapply(171:254, function(i) get_Comtrade(r = country_id[i], cc = "170111"))
dt = sugar_data[!is.na(sugar_data)]
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
chunk3 = DT
chunk123 = rbind(chunk12,chunk3)
DT = chunk123
write.csv(DT, file = "/Users/bendenisshaffer/Box Sync/UM Fall 2017/SI 608/Project/Data/sugar_trade.csv")
DTT = DT %>% select(Reporter,Partner,Trade_Value__US__,Netweight__kg_,
Reporter_ISO, Partner_ISO, Commodity, Year) %>% filter(Partner != "World", Reporter != "World")
write.csv(DTT, file = "/Users/bendenisshaffer/Box Sync/UM Fall 2017/SI 608/Project/Data/clean_sugar_trade.csv")
coffee_data = lapply(1:84, function(i) get_Comtrade(r = country_id[i]))
dt = coffee_data[!is.na(coffee_data)]
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
head(DT)
chunk1 = DT
coffee_data = lapply(85:172, function(i) get_Comtrade(r = country_id[i]))
dt = coffee_data[!is.na(coffee_data)]
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
chunk2 = DT
chunk12 = rbind(chunk1,chunk2)
length(country_id)
coffee_data = lapply(173:254, function(i) get_Comtrade(r = country_id[i]))
dt = coffee_data[!is.na(coffee_data)]
DT = rbind(dt[[1]],dt[[2]])
for(i in 3:length(dt)){
DT = rbind(DT,dt[[i]])
}
colnames(DT) = str_replace_all(names(DT),"\\.","_")
chunk3 = DT
chunk123 = rbind(chunk12,chunk3)
DT = chunk123
write.csv(DT, file = "/Users/bendenisshaffer/Box Sync/UM Fall 2017/SI 608/Project/Data/coffee_trade.csv")
DTT = DT %>% select(Reporter,Partner,Trade_Value__US__,Netweight__kg_,
Reporter_ISO, Partner_ISO, Commodity, Year) %>% filter(Partner != "World", Reporter != "World")
write.csv(DTT, file = "/Users/bendenisshaffer/Box Sync/UM Fall 2017/SI 608/Project/Data/clean_coffee_trade.csv")
qqnorm(rcauchy(100))
qqnorm(rcauchy(1000))
qqnorm(rcauchy(10000))
qqnorm(rcauchy(10000) + rnorm(1000))
rand = rnorm(100)
hist(rand)
plot(density(rand))
rug(rand)
rand = rnorm(1000)
rand
rand = rnorm(1)
rand
hist(rand)
density(rand)
rand = rnorm(2)
hist(rand)
density(rand)
plot(density(rand))
rand = rnorm(1000)
hist(rand)
plot(density(rand))
rug(rand)
library(tidyverse)
library(tmap)
library(plyr)
library(igraph)
library(dplyr)
library(parallel)
library(purrr)
library(stringr)
source("Analysis/remove_self_node.R")
source("Analysis/compute_triplets.R")
source("Analysis/compute_all_triplets.R")
source("Analysis/categorize_all_triplets.R")
source("Analysis/categorize_triplet1.R")
coffeeG05 = read_graph("Data/iGraphs/coffeeG05.gml", format = "gml")
coffeeG10 = read_graph("Data/iGraphs/coffeeG10.gml", format = "gml")
coffeeG15 = read_graph("Data/iGraphs/coffeeG15.gml", format = "gml")
ecount(coffeeG05)
vcount(coffeeG05)
transitivity(coffeeG05)
average.path.length(coffeeG05)
edge_density(coffeeG05)
v = c(size = ecount(coffeeG05),
order = vcount(coffeeG05),
transitivity = transitivity(coffeeG05),
average_path_length = average.path.length(coffeeG05),
edge_density = edge_density(coffeeG05))
data.frame(graph_measures = v)
par(mfrow = c(2,2))
plot(degree_distribution(coffeeG05, mode ="out", cumulative = T), type = "l", col = 2)
lines(degree_distribution(coffeeG05, mode ="in", cumulative = T), col = 3)
plot(density(log(degree_distribution(coffeeG05, mode ="out", cumulative = F))), type = "l", col = 2)
lines(density(log(degree_distribution(coffeeG05, mode ="in", cumulative = F))), col = 3)
plot(density(log(betweenness(coffeeG05))), col = 4)
plot(density(closeness(coffeeG05)), col = 4)
all_triplets = compute_all_triplets(coffeeG05, "Switzerland:CHE")
barplot(table(all_triplets$category)/sum(table(all_triplets$category)))
plot(density(log(degree_distribution(coffeeG05, mode ="out", cumulative = F))),
type = "l", col = 2, main = "Log Degree Centrality Distribution", ylim = c(0,0.5))
lines(density(log(degree_distribution(coffeeG05, mode ="in", cumulative = F))), col = 3)
abline(v = log(degree(coffeeG05, v = "Ethiopia:ETH", mode = "out")), lty = 4, col = 2)
abline(v = log(degree(graph(), v = input$select_countries, mode = "in")), lty = 4, col = 3)
legend("topright", legend = list("Out Degree", "In Degree"), lty = c(1,1), col = c(2,3))
setwd("~/Box Sync/UM Fall 2017/SI 608/CoffeeTradeNetworkProject")
library(tidyverse)
library(tmap)
library(plyr)
library(igraph)
library(dplyr)
library(parallel)
library(purrr)
library(stringr)
source("Analysis/remove_self_node.R")
source("Analysis/compute_triplets.R")
source("Analysis/compute_all_triplets.R")
source("Analysis/categorize_all_triplets.R")
source("Analysis/categorize_triplet1.R")
coffeeG05 = read_graph("Data/iGraphs/coffeeG05.gml", format = "gml")
coffeeG10 = read_graph("Data/iGraphs/coffeeG10.gml", format = "gml")
coffeeG15 = read_graph("Data/iGraphs/coffeeG15.gml", format = "gml")
ecount(coffeeG05)
vcount(coffeeG05)
transitivity(coffeeG05)
average.path.length(coffeeG05)
edge_density(coffeeG05)
v = c(size = ecount(coffeeG05),
order = vcount(coffeeG05),
transitivity = transitivity(coffeeG05),
average_path_length = average.path.length(coffeeG05),
edge_density = edge_density(coffeeG05))
data.frame(graph_measures = v)
par(mfrow = c(2,2))
plot(degree_distribution(coffeeG05, mode ="out", cumulative = T), type = "l", col = 2)
lines(degree_distribution(coffeeG05, mode ="in", cumulative = T), col = 3)
plot(density(log(degree_distribution(coffeeG05, mode ="out", cumulative = F))), type = "l", col = 2)
lines(density(log(degree_distribution(coffeeG05, mode ="in", cumulative = F))), col = 3)
plot(density(log(betweenness(coffeeG05))), col = 4)
plot(density(closeness(coffeeG05)), col = 4)
all_triplets = compute_all_triplets(coffeeG05, "Switzerland:CHE")
barplot(table(all_triplets$category)/sum(table(all_triplets$category)))
plot(density(log(degree_distribution(coffeeG05, mode ="out", cumulative = F))),
type = "l", col = 2, main = "Log Degree Centrality Distribution", ylim = c(0,0.5))
lines(density(log(degree_distribution(coffeeG05, mode ="in", cumulative = F))), col = 3)
abline(v = log(degree(coffeeG05, v = "Ethiopia:ETH", mode = "out")), lty = 4, col = 2)
abline(v = log(degree(graph(), v = input$select_countries, mode = "in")), lty = 4, col = 3)
legend("topright", legend = list("Out Degree", "In Degree"), lty = c(1,1), col = c(2,3))
setwd("~/Google Drive (shafferbendenis@gmail.com)/Coffee_Trade_Network_Modeling_Project")
require(tmap)
require(plyr)
require(network)
require(ergm)
require(igraph)
require(stringr)
#Import that data
data(World)
coffeeG05 = read_graph("data/igraphs/coffeeG05.gml", format = "gml")
coffeeG10 = read_graph("data/igraphs/coffeeG10.gml", format = "gml")
#Extract names of countries that are present in both the 2005 and 2010 networks
G10names = vertex.attributes(coffeeG10)$name
G05names = vertex.attributes(coffeeG05)$name
G10names = G10names[G10names %in% G05names]
iso_a3 = str_replace(str_extract(G10names,":[A-Z]*"),":","")
DT = data.frame(name = G10names, iso_a3)
#Join the World data and the data.frame of names by the ISO code
DT = join(DT, World@data, by = "iso_a3")
#Subset the network to cases that are present in both 2005 and 2010
coffeeG10sub = induced_subgraph(coffeeG10, vids = G10names)
coffeeG05sub = induced_subgraph(coffeeG05, vids = G10names)
#Add the data to the network data object
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Continent", value = DT$continent)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Subregion", value = DT$subregion)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Population", value = DT$pop_est)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "GDP", value = DT$gdp_cap_est)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Economy", value = DT$economy)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "IncomeLev", value = DT$income_grp)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Area", value = DT$area)
#Adding centrality measures from previous year
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Betweenness", value = betweenness(coffeeG05sub))
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Closeness", value = closeness(coffeeG05sub))
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "InDegree", value = degree(coffeeG05sub, mode = "in"))
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "OutDegree", value = degree(coffeeG05sub, mode = "out"))
#Subset the network further to cases that have complete data: There are 153 countries as a result
VDT = get.data.frame(coffeeG10sub, what = "vertices")
coffeeG10sub = induced_subgraph(coffeeG10sub, vids = VDT$name[complete.cases(VDT)])
#Converting the igraph to a network Object
A = get.adjacency(coffeeG10sub)
VDT = get.data.frame(coffeeG10sub, what = "vertices")
net = as.network(as.matrix(A), directed = TRUE)
network::set.vertex.attribute(net, "GDP", VDT$GDP)
network::set.vertex.attribute(net, "Subregion",VDT$Subregion)
network::set.vertex.attribute(net, "Population", VDT$Population)
network::set.vertex.attribute(net, "Economy", VDT$Economy)
network::set.vertex.attribute(net, "IncomeLev", VDT$IncomeLev)
network::set.vertex.attribute(net, "Continent", VDT$Continent)
network::set.vertex.attribute(net, "Betweenness", VDT$Betweenness)
network::set.vertex.attribute(net, "Closeness", VDT$Closeness)
network::set.vertex.attribute(net, "InDegree", VDT$InDegree)
network::set.vertex.attribute(net, "OutDegree", VDT$OutDegree)
net
save(net, file = "saved_output/objects/net.RData")
load("saved_output/objects/net.RData")
cntr = control.ergm(parallel = 8, MCMLE.maxit = 20)
form0 = formula(net ~ edges)
form1 = formula(net ~ edges + mutual)
form2 = formula(net ~ edges + mutual + nodecov("GDP"))
form3 = formula(net ~ edges + mutual + nodemain("GDP") + nodemain("Population"))
form4 = formula(net ~ edges + mutual + nodemain("GDP") + nodemain("Population")
+ match("Economy") + match("Continent") + match("Subregion"))
form5 = formula(net ~ gwesp(2))
form6 = formula(net ~ edges + gwesp(2))
form7 = formula(net ~ edges + mutual + nodemain("Betweenness"))
form8 = formula(net ~ edges + mutual + nodemain("InDegree"))
form_list = list(form0, form1, form2, form3, form4, form5, form6, form7, form8)
ergm_models = lapply(form_list, function(x) ergm(formula = x, control = cntr))
ergm_models
save(ergm_models, file = "saved_output/objects/ergm_models.RData")
ergm_summaries = lapply(ergm_models, summary)
save(ergm_summaries, file = "saved_output/objects/ergm_summaries.RData")
load("saved_output/objects/ergm_models.RData")
rsqr = lapply(ergm_models, function(x) as.numeric(1 - x$mle.lik/x$null.lik))
AICs = lapply(ergm_models, AIC)
ff = function(mod){
f = as.matrix(mod$newnetwork)
dim(f) = c(length(y),1)
p = sum(diag(table(f,y)))/sum(table(f,y))
p
}
preds = lapply(ergm_models, ff)
load("saved_output/objects/net.RData")
y = as.matrix(net)
dim(y) = c(ncol(y)^2,1)
n = 30
errors0 = vector(mode = "numeric", length = n)
for(i in 1:length(errors0)){
fitted0 = as.matrix(get.adjacency(sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))))
dim(fitted0) = c(length(y),1)
pred0 = table(y, fitted0)
errors0[i] = sum(diag(pred0))/sum(pred0)
}
errors = lapply(form_list[-c(1,6,7)], function(x) get_pred_sample(form = x, cntr, n, y))
source("functions/pred_sample.R")
errors = lapply(form_list[-c(1,6,7)], function(x) get_pred_sample(form = x, cntr, n, y))
cntr = control.ergm(parallel = 8, MCMLE.maxit = 20)
form0 = formula(net ~ edges)
form1 = formula(net ~ edges + mutual)
form2 = formula(net ~ edges + mutual + nodecov("GDP"))
form3 = formula(net ~ edges + mutual + nodemain("GDP") + nodemain("Population"))
form4 = formula(net ~ edges + mutual + nodemain("GDP") + nodemain("Population")
+ match("Economy") + match("Continent") + match("Subregion"))
form5 = formula(net ~ gwesp(2))
form6 = formula(net ~ edges + gwesp(2))
form7 = formula(net ~ edges + mutual + nodemain("Betweenness"))
form8 = formula(net ~ edges + mutual + nodemain("InDegree"))
form_list = list(form0, form1, form2, form3, form4, form5, form6, form7, form8)
errors = lapply(form_list[-c(1,6,7)], function(x) get_pred_sample(form = x, cntr, n, y))
save(errors, file = "saved_output/objects/errors.RData")
load("saved_output/objects/ergm_models.RData")
load("saved_output/objects/net.RData")
y = as.matrix(net)
dim(y) = c(ncol(y)^2,1)
n = 30
errors0 = vector(mode = "numeric", length = n)
for(i in 1:length(errors0)){
fitted0 = as.matrix(get.adjacency(sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))))
dim(fitted0) = c(length(y),1)
pred0 = table(y, fitted0)
errors0[i] = sum(diag(pred0))/sum(pred0)
}
rsqr = lapply(ergm_models, function(x) as.numeric(1 - x$mle.lik/x$null.lik))
AICs = lapply(ergm_models, AIC)
ff = function(mod){
f = as.matrix(mod$newnetwork)
dim(f) = c(length(y),1)
p = sum(diag(table(f,y)))/sum(table(f,y))
p
}
preds = lapply(ergm_models, ff)
res = data.frame(r2 = unlist(rsqr), AIC = unlist(AICs), correct = unlist(preds))
row.names(res) = form_list
res$correct[1] = mean(errors0)
ergm_models[[1]]
ergm_models[[1]]$formula
lapply(ergm_models, function(x) x$formula)
row.names(res) = unlist(lapply(ergm_models, function(x) x$formula))
res
view(res)
View(res)
save(res, "saved_output/objects/res.RData")
save(res, file = "saved_output/objects/res.RData")
load("saved_output/objects/errors.RData")
load("saved_output/objects/net.RData")
y = as.matrix(net)
dim(y) = c(ncol(y)^2,1)
n = 30
errors0 = vector(mode = "numeric", length = n)
for(i in 1:length(errors0)){
fitted0 = as.matrix(get.adjacency(sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))))
dim(fitted0) = c(length(y),1)
pred0 = table(y, fitted0)
errors0[i] = sum(diag(pred0))/sum(pred0)
}
load("saved_output/objects/ergm_models.RData")
n = 30
errors0 = vector(mode = "numeric", length = n)
for(i in 1:length(errors0)){
fitted0 = as.matrix(get.adjacency(sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))))
dim(fitted0) = c(length(y),1)
pred0 = table(y, fitted0)
errors0[i] = sum(diag(pred0))/sum(pred0)
}
pvals = c(t.test(errors0, errors[[1]])$p.value,
t.test(errors[[1]], errors[[2]])$p.value,
t.test(errors[[2]], errors[[3]])$p.value,
t.test(errors[[3]], errors[[4]])$p.value,
t.test(errors[[4]], errors[[5]])$p.value,
t.test(errors[[5]], errors[[6]])$p.value)
test_names = c("m1 vs m2", "m2 vs m3", "m3 vs m4", "m4 vs m5", "m5 vs m6", "m6 vs m7")
tests = data.frame(test = test_names, p_value = pvals)
tests
save(tests, file = "saved_output/objects/tests.RData")
gdf = cbind(unlist(errors0),errors)
names(gdf) = 1:ncol(gdf)
gdff = gather(gdf, "Model", "Accuracy")
require(tidyr)
gdff = gather(gdf, "Model", "Accuracy")
gdf = cbind(unlist(errors0),errors)
names(gdf) = 1:ncol(gdf)
gdff = gather(gdf, "Model", "Accuracy")
gdf
errors0
errors
tests
gdf
data.frame(errors)
gdf = cbind(unlist(errors0),data.frame(errors))
names(gdf) = 1:ncol(gdf)
gdff = gather(gdf, "Model", "Accuracy")
g = ggplot(gdff, aes(x = Accuracy, fill = Model)) +
geom_density(alpha = 0.2) +
labs(title = "Density of Edge Presence Prediction")
require(ggplot2)
g = ggplot(gdff, aes(x = Accuracy, fill = Model)) +
geom_density(alpha = 0.2) +
labs(title = "Density of Edge Presence Prediction")
g
ggsave(filename = "saved_output/plots/test_density_plot.png", device = "png")
require(igraph)
require(network)
require(igraph)
require(network)
load("saved_output/objects/ergm_models.RData")
resG = lapply(ergm_models[c(5,7)], function(x) graph_from_edgelist(as.edgelist(x$newnetwork)))
ERgraph = sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))
load("saved_output/objects/net.RData")
y = as.matrix(net)
dim(y) = c(ncol(y)^2,1)
ERgraph = sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))
resG = list(coffeeG10sub, resG[[1]], resG[[2]], ERgraph)
coffeeG05 = read_graph("Data/iGraphs/coffeeG05.gml", format = "gml")
coffeeG10 = read_graph("Data/iGraphs/coffeeG10.gml", format = "gml")
coffeeG15 = read_graph("Data/iGraphs/coffeeG15.gml", format = "gml")
gasG05 = read_graph("Data/iGraphs/gasG05.gml", format = "gml")
gasG10 = read_graph("Data/iGraphs/gasG10.gml", format = "gml")
gasG15 = read_graph("Data/iGraphs/gasG15.gml", format = "gml")
sugarG05 = read_graph("Data/iGraphs/sugarG05.gml", format = "gml")
sugarG10 = read_graph("Data/iGraphs/sugarG10.gml", format = "gml")
sugarG15 = read_graph("Data/iGraphs/sugarG15.gml", format = "gml")
source("Analysis/pred_sample.R")
#Import that data
data(World)
coffeeG05 = read_graph("Data/iGraphs/coffeeG05.gml", format = "gml")
coffeeG10 = read_graph("Data/iGraphs/coffeeG10.gml", format = "gml")
#Extract names of countries that are present in both the 2005 and 2010 networks
G10names = vertex.attributes(coffeeG10)$name
G05names = vertex.attributes(coffeeG05)$name
G10names = G10names[G10names %in% G05names]
iso_a3 = str_replace(str_extract(G10names,":[A-Z]*"),":","")
DT = data.frame(name = G10names, iso_a3)
#Join the World data and the data.frame of names by the ISO code
DT = join(DT, World@data, by = "iso_a3")
#Subset the network to cases that are present in both 2005 and 2010
coffeeG10sub = induced_subgraph(coffeeG10, vids = G10names)
coffeeG05sub = induced_subgraph(coffeeG05, vids = G10names)
#Add the data to the network data object
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Continent", value = DT$continent)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Subregion", value = DT$subregion)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Population", value = DT$pop_est)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "GDP", value = DT$gdp_cap_est)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Economy", value = DT$economy)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "IncomeLev", value = DT$income_grp)
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Area", value = DT$area)
#Adding centrality measures from previous year
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Betweenness", value = betweenness(coffeeG05sub))
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "Closeness", value = closeness(coffeeG05sub))
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "InDegree", value = degree(coffeeG05sub, mode = "in"))
coffeeG10sub = set_vertex_attr(coffeeG10sub, name = "OutDegree", value = degree(coffeeG05sub, mode = "out"))
#Subset the network further to cases that have complete data: There are 153 countries as a result
VDT = get.data.frame(coffeeG10sub, what = "vertices")
coffeeG10sub = induced_subgraph(coffeeG10sub, vids = VDT$name[complete.cases(VDT)])
write_graph(coffeeG10sub, "data/igraphs/coffeeG10sub.gml", format = "gml")
coffeeG10sub = read_graph("data/igraphs/coffeeG10sub.gml")
?read.graph
coffeeG10sub = read_graph("data/igraphs/coffeeG10sub.gml", format = "gml")
require(igraph)
require(network)
load("saved_output/objects/net.RData")
load("saved_output/objects/ergm_models.RData")
coffeeG10sub = read_graph("data/igraphs/coffeeG10sub.gml", format = "gml")
resG = lapply(ergm_models[c(5,7)], function(x) graph_from_edgelist(as.edgelist(x$newnetwork)))
y = as.matrix(net)
dim(y) = c(ncol(y)^2,1)
ERgraph = sample_gnp(sqrt(length(y)), exp(ergm_models[[1]]$coef))
resG = list(coffeeG10sub, resG[[1]], resG[[2]], ERgraph)
resGsize = lapply(resG, ecount)
resGorder = lapply(resG, vcount)
resGtransitivity = lapply(resG, transitivity)
resGaverage_path_length = lapply(resG, average.path.length)
resGedge_density = lapply(resG, edge_density)
kable(data.frame(Size = unlist(resGsize),
Order = unlist(resGorder),
Transitivity = unlist(resGtransitivity),
Average_Path_Length = unlist(resGaverage_path_length),
Edge_Density = unlist(resGedge_density),
Model = c("Original Network","Fith Model","GWESP Model","ER Model")))
data.frame(Size = unlist(resGsize),
Order = unlist(resGorder),
Transitivity = unlist(resGtransitivity),
Average_Path_Length = unlist(resGaverage_path_length),
Edge_Density = unlist(resGedge_density),
Model = c("Original Network","Fith Model","GWESP Model","ER Model"))
comparison_table =  data.frame(Size = unlist(resGsize),
Order = unlist(resGorder),
Transitivity = unlist(resGtransitivity),
Average_Path_Length = unlist(resGaverage_path_length),
Edge_Density = unlist(resGedge_density),
Model = c("Original Network","Fith Model","GWESP Model","ER Model"))
?save
save(comparison_table, file = "saved_output/objects/comparison_table.RData")
